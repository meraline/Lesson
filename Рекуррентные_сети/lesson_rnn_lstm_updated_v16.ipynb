{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импорт библиотек\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2fd796b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_dataloader(x, y, batch_size=64, shuffle=True):\n",
    "    dataset = TensorDataset(x, y)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Упрощенный метод генерации данных\n",
    "tensor_10 = torch.randint(10, (1000, 10))  # 1000 последовательностей по 10 элементов каждая\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Обновленная функция трансформации\n",
    "def transform(tensor):\n",
    "    y = torch.zeros_like(tensor)\n",
    "    for j in range(len(y)):\n",
    "        for i in range(len(y[1,:])):\n",
    "            y[j,0] = tensor[j,0]\n",
    "            y[j,i] = (tensor[j,i] + y[j,0]) % 10\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Функция для создания наборов данных\n",
    "def create_datasets(num_samples=1000, sequence_length=10):\n",
    "    # Генерация исходных данных\n",
    "    x_data = torch.randint(10, (num_samples, sequence_length))\n",
    "\n",
    "    # Преобразование данных\n",
    "    y_data = transform(x_data)\n",
    "\n",
    "    # Создание TensorDataset\n",
    "    dataset = TensorDataset(x_data, y_data)\n",
    "    return dataset\n",
    "\n",
    "# Создание обучающего и тестового наборов данных\n",
    "train_dataset = create_datasets()\n",
    "test_dataset = create_datasets(num_samples=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "647ef2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Создание обучающих и тестовых наборов данных\n",
    "train_dataset_10 = create_datasets(num_samples=1000, sequence_length=10)\n",
    "test_dataset_10 = create_datasets(num_samples=200, sequence_length=10)\n",
    "\n",
    "train_dataset_40 = create_datasets(num_samples=1000, sequence_length=40)\n",
    "test_dataset_40 = create_datasets(num_samples=200, sequence_length=40)\n",
    "\n",
    "train_dataset_80 = create_datasets(num_samples=1000, sequence_length=80)\n",
    "test_dataset_80 = create_datasets(num_samples=200, sequence_length=80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Создание даталоадеров для обучающих и тестовых наборов данных\n",
    "train_loader_10 = create_dataloader(train_dataset_10.tensors[0], train_dataset_10.tensors[1], batch_size=64, shuffle=True)\n",
    "test_loader_10 = create_dataloader(test_dataset_10.tensors[0], test_dataset_10.tensors[1], batch_size=64, shuffle=False)\n",
    "\n",
    "train_loader_40 = create_dataloader(train_dataset_40.tensors[0], train_dataset_40.tensors[1], batch_size=64, shuffle=True)\n",
    "test_loader_40 = create_dataloader(test_dataset_40.tensors[0], test_dataset_40.tensors[1], batch_size=64, shuffle=False)\n",
    "\n",
    "train_loader_80 = create_dataloader(train_dataset_80.tensors[0], train_dataset_80.tensors[1], batch_size=64, shuffle=True)\n",
    "test_loader_80 = create_dataloader(test_dataset_80.tensors[0], test_dataset_80.tensors[1], batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Шаг 2: Определение архитектур моделей\n",
    "\n",
    "class MyRecurrentNet(nn.Module):\n",
    "    def __init__(self, rnn_class, seq_len, input_size, hidden_size, num_classes):\n",
    "        super(MyRecurrentNet, self).__init__()\n",
    "        self.embedding = nn.Embedding(10, input_size)\n",
    "        self.rnn = rnn_class(input_size=input_size, hidden_size=hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        out, _ = self.rnn(x)\n",
    "        # Теперь 'out' имеет размерность (batch_size, seq_len, hidden_size)\n",
    "        out = self.fc(out)\n",
    "        # 'out' после этого имеет размерность (batch_size, seq_len, num_classes)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_MyLSTM = MyRecurrentNet(nn.LSTM, seq_len=10, input_size=10, hidden_size=64, num_classes=10)\n",
    "model_MyRNN = MyRecurrentNet(nn.RNN, seq_len=10, input_size=10, hidden_size=64, num_classes=10)\n",
    "model_MyGRU = MyRecurrentNet(nn.GRU, seq_len=10, input_size=10, hidden_size=64, num_classes=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Шаг 3: Обучение моделей\n",
    "\n",
    "# Функция для обучения модели\n",
    "def train_model(model, train_loader, criterion, optimizer, num_classes, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for x, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x)\n",
    "            # Преобразование выходных данных модели для соответствия размерности целевых данных\n",
    "            outputs = outputs.view(-1, num_classes)  # Размерность теперь [batch_size * sequence_length, num_classes]\n",
    "            y = y.view(-1)  # Преобразование y к одномерному вектору\n",
    "            # Вычисление потерь\n",
    "            loss = criterion(outputs, y.long())  # Убедитесь, что y имеет тип LongTensor\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN       0.0490         9.45           0.0482         9.40           0.0480         9.68           \n",
      "LSTM      0.0493         10.30          0.0482         9.61           0.0480         9.74           \n",
      "GRU       0.0487         9.30           0.0482         9.29           0.0479         10.14          \n"
     ]
    }
   ],
   "source": [
    "# Цикл по типам моделей\n",
    "for model_type in [\"RNN\", \"LSTM\", \"GRU\"]:\n",
    "    row = f\"{model_type:<10}\"\n",
    "    \n",
    "    # Цикл по длинам последовательностей\n",
    "    for seq_len, train_loader, test_loader in zip([10, 40, 80], [train_loader_10, train_loader_40, train_loader_80], [test_loader_10, test_loader_40, test_loader_80]):\n",
    "        # Создаем экземпляр модели в зависимости от типа и длины последовательности\n",
    "        if model_type == \"RNN\":\n",
    "            model = MyRecurrentNet(nn.RNN, seq_len=seq_len, input_size=10, hidden_size=64, num_classes=10)\n",
    "        elif model_type == \"LSTM\":\n",
    "            model = MyRecurrentNet(nn.LSTM, seq_len=seq_len, input_size=10, hidden_size=64, num_classes=10)\n",
    "        elif model_type == \"GRU\":\n",
    "            model = MyRecurrentNet(nn.GRU, seq_len=seq_len, input_size=10, hidden_size=64, num_classes=10)\n",
    "        \n",
    "        # Определяем функцию потерь и оптимизатор\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        \n",
    "        # Обучаем модель\n",
    "        train_model(model, train_loader, criterion, optimizer, num_classes=10)\n",
    "        \n",
    "        # Инициализация переменных для оценки производительности\n",
    "        test_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        num_classes = 10\n",
    "\n",
    "        # Оценка производительности на тестовых данных\n",
    "        with torch.no_grad():\n",
    "            for x, y in test_loader:\n",
    "                outputs = model(x)\n",
    "                outputs = outputs.view(-1, num_classes)  # Преобразуем выходные данные модели\n",
    "\n",
    "                # Повторяем каждый элемент y seq_len раз\n",
    "                y_expanded = y.repeat_interleave(seq_len)\n",
    "                y_expanded = y_expanded[:outputs.size(0)]  # Обрезаем y_expanded, чтобы соответствовать размеру outputs\n",
    "\n",
    "                # Вычисляем потери\n",
    "                test_loss += criterion(outputs, y_expanded).item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += y.size(0) * seq_len\n",
    "                correct += (predicted == y_expanded).sum().item()\n",
    "\n",
    "                # Расчет средней потери и точности\n",
    "                test_loss /= len(test_loader)\n",
    "                accuracy = 100 * correct / total\n",
    "\n",
    "\n",
    "\n",
    "        # Расчет средней потери и точности\n",
    "        test_loss /= len(test_loader)\n",
    "        accuracy = 100 * correct / total\n",
    "        row += f\"{test_loss/len(test_loader):<15.4f}{accuracy:<15.2f}\"\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель      Длина послед.  Потери (ср.)   Точность (%)\n",
      "RNN         10               2.3561           9.60           \n",
      "RNN         40               2.3169           9.49           \n",
      "RNN         80               2.3084           9.54           \n",
      "LSTM        10               2.3443           10.25          \n",
      "LSTM        40               2.3118           9.57           \n",
      "LSTM        80               2.3076           9.04           \n",
      "GRU         10               2.3421           9.35           \n",
      "GRU         40               2.3158           9.43           \n",
      "GRU         80               2.3069           9.66           \n"
     ]
    }
   ],
   "source": [
    "# Шаг 4: Оценка производительности моделей\n",
    "\n",
    "# Создаем заголовок для таблички с результатами\n",
    "print(\"Модель      Длина послед.  Потери (ср.)   Точность (%)\")\n",
    "\n",
    "for model_type in [\"RNN\", \"LSTM\", \"GRU\"]:\n",
    "    # Цикл по длинам последовательностей\n",
    "    for seq_len, train_loader, test_loader in zip([10, 40, 80], [train_loader_10, train_loader_40, train_loader_80], [test_loader_10, test_loader_40, test_loader_80]):\n",
    "        # Создаем экземпляр модели в зависимости от типа и длины последовательности\n",
    "        if model_type == \"RNN\":\n",
    "            model = MyRecurrentNet(nn.RNN, seq_len=seq_len, input_size=10, hidden_size=64, num_classes=10)\n",
    "        elif model_type == \"LSTM\":\n",
    "            model = MyRecurrentNet(nn.LSTM, seq_len=seq_len, input_size=10, hidden_size=64, num_classes=10)\n",
    "        elif model_type == \"GRU\":\n",
    "            model = MyRecurrentNet(nn.GRU, seq_len=seq_len, input_size=10, hidden_size=64, num_classes=10)\n",
    "        \n",
    "        # Определяем функцию потерь и оптимизатор\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        \n",
    "        # Обучаем модель\n",
    "        train_model(model, train_loader, criterion, optimizer, num_classes=10)\n",
    "        \n",
    "        # Инициализация переменных для оценки производительности\n",
    "        test_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        num_classes = 10\n",
    "\n",
    "        # Оценка производительности на тестовых данных\n",
    "        with torch.no_grad():\n",
    "            for x, y in test_loader:\n",
    "                outputs = model(x)\n",
    "                outputs = outputs.view(-1, num_classes)  # Преобразуем выходные данные модели\n",
    "\n",
    "                # Повторяем каждый элемент y seq_len раз\n",
    "                y_expanded = y.repeat_interleave(seq_len)\n",
    "                y_expanded = y_expanded[:outputs.size(0)]  # Обрезаем y_expanded, чтобы соответствовать размеру outputs\n",
    "\n",
    "                # Вычисляем потери\n",
    "                test_loss += criterion(outputs, y_expanded).item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += y.size(0) * seq_len\n",
    "                correct += (predicted == y_expanded).sum().item()\n",
    "\n",
    "        # Расчет средней потери и точности\n",
    "        test_loss /= len(test_loader)\n",
    "        accuracy = 100 * correct / total\n",
    "\n",
    "        # Вывод результатов для текущей модели и длины последовательности\n",
    "        print(f\"{model_type:<10}  {seq_len:<15}  {test_loss:<15.4f}  {accuracy:<15.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TorchEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
