{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7J2ylU2s8v5"
      },
      "source": [
        "## Архитектуры свёрточных сетей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-18T16:19:19.017474Z",
          "start_time": "2019-11-18T16:19:18.970512Z"
        },
        "id": "y0aUeYwa07Np"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torchvision as tv\n",
        "from torchsummary import summary\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-18T16:20:21.306023Z",
          "start_time": "2019-11-18T16:20:21.293827Z"
        },
        "id": "uwaCmLfh07Nx"
      },
      "outputs": [],
      "source": [
        "def evaluate_accuracy(data_iter, net):\n",
        "    acc_sum, n = 0, 0\n",
        "    net.eval()\n",
        "    for X, y in data_iter:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        acc_sum += (net(X).argmax(axis=1) == y).sum()\n",
        "        n += y.shape[0]\n",
        "    return acc_sum.item() / n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-18T16:20:21.693926Z",
          "start_time": "2019-11-18T16:20:21.678441Z"
        },
        "id": "mHmVyS9O07Nz"
      },
      "outputs": [],
      "source": [
        "def train(net, train_iter, test_iter, trainer, num_epochs):\n",
        "    net.to(device)\n",
        "    loss = nn.CrossEntropyLoss(reduction='sum')\n",
        "    net.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
        "        \n",
        "        for i, (X, y) in enumerate(train_iter):\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            trainer.zero_grad()\n",
        "            y_hat = net(X)\n",
        "            l = loss(y_hat, y)\n",
        "            l.backward()\n",
        "            trainer.step()\n",
        "            train_l_sum += l.item()\n",
        "            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\n",
        "            n += y.shape[0]\n",
        "\n",
        "            if i % 10 == 0:\n",
        "              print(f\"Step {i}. time since epoch: {time.time() -  start:.3f}. \" \n",
        "                    f\"Train acc: {train_acc_sum / n:.3f}. Train Loss: {train_l_sum / n:.3f}\")\n",
        "        test_acc = evaluate_accuracy(test_iter, net.to(device))\n",
        "        print('-' * 20)\n",
        "        print(f'epoch {epoch + 1}, loss {train_l_sum / n:.4f}, train acc {train_acc_sum / n:.3f}'\n",
        "              f', test acc {test_acc:.3f}, time {time.time() - start:.1f} sec')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "xjRzZazUBBhE",
        "outputId": "94337aed-388f-49cd-cdcf-c491c89d31de"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#torch.backends.cuda.max_split_size_mb = 10000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaVsexlm07Ns"
      },
      "source": [
        "## DataSet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-18T16:24:00.569981Z",
          "start_time": "2019-11-18T16:24:00.510393Z"
        },
        "id": "E0-WXQPV07N6"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 192\n",
        "transoforms = tv.transforms.Compose([\n",
        "    tv.transforms.Resize((224, 224)),\n",
        "    tv.transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_dataset = tv.datasets.EMNIST('../data', split='balanced', train=True, download=True, transform=transoforms)\n",
        "test_dataset = tv.datasets.EMNIST('../data', split='balanced', train=False, download=True, transform=transoforms)\n",
        "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
        "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g55sb1uP07ON"
      },
      "source": [
        "## Предобученные архитектуры"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-18T17:21:46.290923Z",
          "start_time": "2019-11-18T17:21:46.236514Z"
        },
        "id": "4l5GE7DA07OO"
      },
      "outputs": [],
      "source": [
        "transoforms = tv.transforms.Compose([\n",
        "    tv.transforms.Grayscale(3),\n",
        "    tv.transforms.Resize((224, 224)),\n",
        "    tv.transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_dataset = tv.datasets.MNIST('.', train=True, transform=transoforms, download=True)\n",
        "test_dataset = tv.datasets.MNIST('.', train=False, transform=transoforms, download=True)\n",
        "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
        "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MENekEq_AHqo"
      },
      "source": [
        "#### ResNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-18T17:22:33.772924Z",
          "start_time": "2019-11-18T17:22:33.293818Z"
        },
        "id": "ju3bFRxI07OO"
      },
      "outputs": [],
      "source": [
        "model = tv.models.resnet18(pretrained=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STGg9M4sDuff",
        "outputId": "08347b00-c844-4fa9-9e5c-9f63d23607c8"
      },
      "outputs": [],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncajlZiCDwUt",
        "outputId": "896dcc46-ce0c-4739-bb4d-0c7bc4b78939"
      },
      "outputs": [],
      "source": [
        "summary(model.to(device), input_size=(3, 224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-18T17:23:47.319979Z",
          "start_time": "2019-11-18T17:23:47.316747Z"
        },
        "id": "QuYMuz8i07OO"
      },
      "outputs": [],
      "source": [
        "# Убираем требование градиента:\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-18T17:24:04.770976Z",
          "start_time": "2019-11-18T17:24:04.766810Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psXlmjnx07OO",
        "outputId": "eb0dbdcc-3845-405a-b906-526ee7e07a72"
      },
      "outputs": [],
      "source": [
        "model.fc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-18T17:24:12.305790Z",
          "start_time": "2019-11-18T17:24:12.302517Z"
        },
        "id": "n637z2fz07OO"
      },
      "outputs": [],
      "source": [
        "model.fc = nn.Linear(in_features=512, out_features=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-18T17:24:42.228326Z",
          "start_time": "2019-11-18T17:24:42.222643Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzYUzBDH07OP",
        "outputId": "b0fa069a-d57a-420d-a264-8e4a092d50ac"
      },
      "outputs": [],
      "source": [
        "print(\"Params to learn:\")\n",
        "params_to_update = []\n",
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad == True:\n",
        "        params_to_update.append(param)\n",
        "        print(\"\\t\",name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-18T17:25:11.558131Z",
          "start_time": "2019-11-18T17:25:11.554358Z"
        },
        "id": "UEWnyfQD07OP"
      },
      "outputs": [],
      "source": [
        "trainer = torch.optim.Adam(params_to_update, lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-18T17:26:20.718099Z",
          "start_time": "2019-11-18T17:25:20.979097Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bzy-TnEs07OP",
        "outputId": "48cc2374-cc2b-4233-8d06-f38b6772268b"
      },
      "outputs": [],
      "source": [
        "train_loss_resnet18 = train(model, train_iter, test_iter, trainer, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yz6qmsROAGcq"
      },
      "source": [
        "#### vgg16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# VGG11\n",
        "model_vgg16 = tv.models.vgg16(pretrained=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-Mfy6xdAGmq",
        "outputId": "b849d21e-7ac0-4416-ee31-9c9fa3d8c752"
      },
      "outputs": [],
      "source": [
        "model_vgg16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-18T17:23:47.319979Z",
          "start_time": "2019-11-18T17:23:47.316747Z"
        },
        "id": "g7d8QjgYAZ_g"
      },
      "outputs": [],
      "source": [
        "# Убираем требование градиента:\n",
        "for param in model_vgg16.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-18T17:24:04.770976Z",
          "start_time": "2019-11-18T17:24:04.766810Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lgexjk8JAZ_j",
        "outputId": "3e9aab48-7962-4898-a5bc-853a990d9391"
      },
      "outputs": [],
      "source": [
        "model_vgg16.classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-18T17:24:12.305790Z",
          "start_time": "2019-11-18T17:24:12.302517Z"
        },
        "id": "uSzRrmxVAZ_l"
      },
      "outputs": [],
      "source": [
        "model_vgg16.classifier = nn.Sequential(\n",
        "    nn.Linear(25088, 4096), \n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(4096, 10)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Распечатать заголовок секции \n",
        "print(\"Params to learn:\")  \n",
        "\n",
        "# Создать пустой список для хранения обучаемых параметров\n",
        "params_to_update = []  \n",
        "\n",
        "# Получить именованные параметры модели в виде списка tuple\n",
        "for name, param in model_vgg16.named_parameters():\n",
        "    \n",
        "    # Проверить флаг requires_grad, который указывает нужно ли обучать этот параметр\n",
        "    if param.requires_grad == True:\n",
        "\n",
        "        # Добавить параметр в список обучаемых\n",
        "        params_to_update.append(param)\n",
        "        \n",
        "        # Распечатать имя параметра с отступом\n",
        "        print(\"\\t\",name)\n",
        "        \n",
        "# Теперь в params_to_update будут только обучаемые параметры модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-18T17:25:11.558131Z",
          "start_time": "2019-11-18T17:25:11.554358Z"
        },
        "id": "wJqgDnKIAZ_o"
      },
      "outputs": [],
      "source": [
        "trainer = torch.optim.Adam(params_to_update, lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-18T17:26:20.718099Z",
          "start_time": "2019-11-18T17:25:20.979097Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqUMukocAZ_o",
        "outputId": "a0788b73-0de1-4542-fd69-c577a3d1c30b"
      },
      "outputs": [],
      "source": [
        "train_loss_vgg16 = train(model_vgg16, train_iter, test_iter, trainer, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### densenet161"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = tv.models.densenet161(pretrained=True)\n",
        "# Убираем требование градиента:\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "model.classifier = nn.Linear(in_features=2208, out_features=10)\n",
        "params_to_update = []\n",
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad == True:\n",
        "        params_to_update.append(param)\n",
        "trainer = torch.optim.Adam(params_to_update, lr=0.001)\n",
        "train_loss_densenet161=train(model, train_iter, test_iter, trainer, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Inception v3 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "BATCH_SIZE = 192\n",
        "transoforms = tv.transforms.Compose([\n",
        "    tv.transforms.Grayscale(3),\n",
        "    tv.transforms.Resize((299, 299)),\n",
        "    tv.transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_dataset = tv.datasets.EMNIST('.', train=True, transform=transoforms, download=True, split='mnist')\n",
        "test_dataset = tv.datasets.EMNIST('.', train=False, transform=transoforms, download=True, split='mnist')\n",
        "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
        "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = tv.models.inception_v3(pretrained=True)\n",
        "model = model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_accuracy(data_iter, net):\n",
        "    acc_sum, n = 0, 0\n",
        "    net.eval()\n",
        "    for X, y in data_iter:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        y_hat = net(X)\n",
        "        acc_sum += (y_hat.argmax(axis=1) == y).sum()\n",
        "        n += y.shape[0]\n",
        "        return 0\n",
        "    return acc_sum.item() / n\n",
        "\n",
        "\n",
        "def train(net, train_iter, test_iter, trainer, num_epochs):\n",
        "    train_loss = []\n",
        "    net.to(device)\n",
        "    loss = nn.CrossEntropyLoss(reduction='sum')\n",
        "    #net.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
        "        net.train()\n",
        "        for i, (X, y) in enumerate(train_iter):\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            trainer.zero_grad()\n",
        "            y_hat = net(X)\n",
        "            l = loss(y_hat[0], y)\n",
        "            l.backward()\n",
        "            trainer.step()\n",
        "            train_l_sum += l.item()\n",
        "            train_acc_sum += (y_hat[0].argmax(axis=1) == y).sum().item()\n",
        "            n += y.shape[0]\n",
        "\n",
        "            if i % 100 == 0:\n",
        "              print(f\"Step {i}. time since epoch: {time.time() -  start:.3f}. \"\n",
        "                    f\"Train acc: {train_acc_sum / n:.3f}. Train Loss: {train_l_sum / n:.3f}\")\n",
        "        test_acc = evaluate_accuracy(test_iter, net.to(device))\n",
        "        print('-' * 20)\n",
        "        train_loss.append(train_l_sum / n)\n",
        "        print(f'epoch {epoch + 1}, loss {train_l_sum / n:.4f}, train acc {train_acc_sum / n:.3f}'\n",
        "              f', test acc {test_acc:.3f}, time {time.time() - start:.1f} sec')\n",
        "    return train_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Убираем требование градиента:\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "model.fc = nn.Linear(in_features=2048, out_features=10)\n",
        "params_to_update = []\n",
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad == True:\n",
        "        params_to_update.append(param)\n",
        "        print(\"\\t\",name)\n",
        "trainer = torch.optim.Adam(params_to_update, lr=0.001)\n",
        "train_loss_inception_v3=train(model, train_iter, test_iter, trainer, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "models = ['ResNet18', 'VGG16', 'DenseNet161', 'InceptionV3']\n",
        "train_losses = [train_loss_resnet18, train_loss_vgg16, train_loss_densenet161, train_loss_inception_v3]\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "for i, loss in enumerate(train_losses):\n",
        "  plt.plot(loss, label=models[i])\n",
        "plt.xlabel('Epoch')  \n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.title('Training Loss Comparison')\n",
        "plt.show()\n",
        "\n",
        "print(\"| Model | Loss |\")\n",
        "print(\"| - | - |\")\n",
        "for i in range(len(models)):\n",
        "  print(f\"| {models[i]} | {train_losses[i][-1]:.3f} |\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
