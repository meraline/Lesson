{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7J2ylU2s8v5"
      },
      "source": [
        "## Архитектуры свёрточных сетей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Анатолий\\source\\repos\\PyTorchtest\\PyTorchtest\\TorchEnv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "c:\\Users\\Анатолий\\source\\repos\\PyTorchtest\\PyTorchtest\\TorchEnv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet161_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet161_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "c:\\Users\\Анатолий\\source\\repos\\PyTorchtest\\PyTorchtest\\TorchEnv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training ResNet18...\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\Анатолий\\Documents\\GitHub\\Lesson\\Уроки\\ДЗ_ Архитектуры сверточных сетей — копия.ipynb Ячейка 2\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/%D0%90%D0%BD%D0%B0%D1%82%D0%BE%D0%BB%D0%B8%D0%B9/Documents/GitHub/Lesson/%D0%A3%D1%80%D0%BE%D0%BA%D0%B8/%D0%94%D0%97_%20%D0%90%D1%80%D1%85%D0%B8%D1%82%D0%B5%D0%BA%D1%82%D1%83%D1%80%D1%8B%20%D1%81%D0%B2%D0%B5%D1%80%D1%82%D0%BE%D1%87%D0%BD%D1%8B%D1%85%20%D1%81%D0%B5%D1%82%D0%B5%D0%B9%20%E2%80%94%20%D0%BA%D0%BE%D0%BF%D0%B8%D1%8F.ipynb#X60sZmlsZQ%3D%3D?line=142'>143</a>\u001b[0m trainers \u001b[39m=\u001b[39m [trainer_resnet18, trainer_vgg16, trainer_densenet161, trainer_inception_v3]\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/%D0%90%D0%BD%D0%B0%D1%82%D0%BE%D0%BB%D0%B8%D0%B9/Documents/GitHub/Lesson/%D0%A3%D1%80%D0%BE%D0%BA%D0%B8/%D0%94%D0%97_%20%D0%90%D1%80%D1%85%D0%B8%D1%82%D0%B5%D0%BA%D1%82%D1%83%D1%80%D1%8B%20%D1%81%D0%B2%D0%B5%D1%80%D1%82%D0%BE%D1%87%D0%BD%D1%8B%D1%85%20%D1%81%D0%B5%D1%82%D0%B5%D0%B9%20%E2%80%94%20%D0%BA%D0%BE%D0%BF%D0%B8%D1%8F.ipynb#X60sZmlsZQ%3D%3D?line=143'>144</a>\u001b[0m model_names \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mResNet18\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mVGG16\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mDenseNet161\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mInceptionV3\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/%D0%90%D0%BD%D0%B0%D1%82%D0%BE%D0%BB%D0%B8%D0%B9/Documents/GitHub/Lesson/%D0%A3%D1%80%D0%BE%D0%BA%D0%B8/%D0%94%D0%97_%20%D0%90%D1%80%D1%85%D0%B8%D1%82%D0%B5%D0%BA%D1%82%D1%83%D1%80%D1%8B%20%D1%81%D0%B2%D0%B5%D1%80%D1%82%D0%BE%D1%87%D0%BD%D1%8B%D1%85%20%D1%81%D0%B5%D1%82%D0%B5%D0%B9%20%E2%80%94%20%D0%BA%D0%BE%D0%BF%D0%B8%D1%8F.ipynb#X60sZmlsZQ%3D%3D?line=145'>146</a>\u001b[0m compare_models(models, train_iters, test_iters, trainers, num_epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, model_names\u001b[39m=\u001b[39;49mmodel_names)\n",
            "\u001b[1;32mc:\\Users\\Анатолий\\Documents\\GitHub\\Lesson\\Уроки\\ДЗ_ Архитектуры сверточных сетей — копия.ipynb Ячейка 2\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/%D0%90%D0%BD%D0%B0%D1%82%D0%BE%D0%BB%D0%B8%D0%B9/Documents/GitHub/Lesson/%D0%A3%D1%80%D0%BE%D0%BA%D0%B8/%D0%94%D0%97_%20%D0%90%D1%80%D1%85%D0%B8%D1%82%D0%B5%D0%BA%D1%82%D1%83%D1%80%D1%8B%20%D1%81%D0%B2%D0%B5%D1%80%D1%82%D0%BE%D1%87%D0%BD%D1%8B%D1%85%20%D1%81%D0%B5%D1%82%D0%B5%D0%B9%20%E2%80%94%20%D0%BA%D0%BE%D0%BF%D0%B8%D1%8F.ipynb#X60sZmlsZQ%3D%3D?line=113'>114</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, model \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(models):\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/%D0%90%D0%BD%D0%B0%D1%82%D0%BE%D0%BB%D0%B8%D0%B9/Documents/GitHub/Lesson/%D0%A3%D1%80%D0%BE%D0%BA%D0%B8/%D0%94%D0%97_%20%D0%90%D1%80%D1%85%D0%B8%D1%82%D0%B5%D0%BA%D1%82%D1%83%D1%80%D1%8B%20%D1%81%D0%B2%D0%B5%D1%80%D1%82%D0%BE%D1%87%D0%BD%D1%8B%D1%85%20%D1%81%D0%B5%D1%82%D0%B5%D0%B9%20%E2%80%94%20%D0%BA%D0%BE%D0%BF%D0%B8%D1%8F.ipynb#X60sZmlsZQ%3D%3D?line=114'>115</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTraining \u001b[39m\u001b[39m{\u001b[39;00mmodel_names[i]\u001b[39m}\u001b[39;00m\u001b[39m...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/%D0%90%D0%BD%D0%B0%D1%82%D0%BE%D0%BB%D0%B8%D0%B9/Documents/GitHub/Lesson/%D0%A3%D1%80%D0%BE%D0%BA%D0%B8/%D0%94%D0%97_%20%D0%90%D1%80%D1%85%D0%B8%D1%82%D0%B5%D0%BA%D1%82%D1%83%D1%80%D1%8B%20%D1%81%D0%B2%D0%B5%D1%80%D1%82%D0%BE%D1%87%D0%BD%D1%8B%D1%85%20%D1%81%D0%B5%D1%82%D0%B5%D0%B9%20%E2%80%94%20%D0%BA%D0%BE%D0%BF%D0%B8%D1%8F.ipynb#X60sZmlsZQ%3D%3D?line=115'>116</a>\u001b[0m     train_loss \u001b[39m=\u001b[39m train(model, train_iters[i], test_iters[i], trainers[i], num_epochs)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/%D0%90%D0%BD%D0%B0%D1%82%D0%BE%D0%BB%D0%B8%D0%B9/Documents/GitHub/Lesson/%D0%A3%D1%80%D0%BE%D0%BA%D0%B8/%D0%94%D0%97_%20%D0%90%D1%80%D1%85%D0%B8%D1%82%D0%B5%D0%BA%D1%82%D1%83%D1%80%D1%8B%20%D1%81%D0%B2%D0%B5%D1%80%D1%82%D0%BE%D1%87%D0%BD%D1%8B%D1%85%20%D1%81%D0%B5%D1%82%D0%B5%D0%B9%20%E2%80%94%20%D0%BA%D0%BE%D0%BF%D0%B8%D1%8F.ipynb#X60sZmlsZQ%3D%3D?line=116'>117</a>\u001b[0m     train_losses\u001b[39m.\u001b[39mappend(train_loss)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/%D0%90%D0%BD%D0%B0%D1%82%D0%BE%D0%BB%D0%B8%D0%B9/Documents/GitHub/Lesson/%D0%A3%D1%80%D0%BE%D0%BA%D0%B8/%D0%94%D0%97_%20%D0%90%D1%80%D1%85%D0%B8%D1%82%D0%B5%D0%BA%D1%82%D1%83%D1%80%D1%8B%20%D1%81%D0%B2%D0%B5%D1%80%D1%82%D0%BE%D1%87%D0%BD%D1%8B%D1%85%20%D1%81%D0%B5%D1%82%D0%B5%D0%B9%20%E2%80%94%20%D0%BA%D0%BE%D0%BF%D0%B8%D1%8F.ipynb#X60sZmlsZQ%3D%3D?line=118'>119</a>\u001b[0m     test_acc \u001b[39m=\u001b[39m evaluate_accuracy(test_iters[i], model\u001b[39m.\u001b[39mto(device))\n",
            "\u001b[1;32mc:\\Users\\Анатолий\\Documents\\GitHub\\Lesson\\Уроки\\ДЗ_ Архитектуры сверточных сетей — копия.ipynb Ячейка 2\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/%D0%90%D0%BD%D0%B0%D1%82%D0%BE%D0%BB%D0%B8%D0%B9/Documents/GitHub/Lesson/%D0%A3%D1%80%D0%BE%D0%BA%D0%B8/%D0%94%D0%97_%20%D0%90%D1%80%D1%85%D0%B8%D1%82%D0%B5%D0%BA%D1%82%D1%83%D1%80%D1%8B%20%D1%81%D0%B2%D0%B5%D1%80%D1%82%D0%BE%D1%87%D0%BD%D1%8B%D1%85%20%D1%81%D0%B5%D1%82%D0%B5%D0%B9%20%E2%80%94%20%D0%BA%D0%BE%D0%BF%D0%B8%D1%8F.ipynb#X60sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(net, train_iter, test_iter, trainer, num_epochs):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/%D0%90%D0%BD%D0%B0%D1%82%D0%BE%D0%BB%D0%B8%D0%B9/Documents/GitHub/Lesson/%D0%A3%D1%80%D0%BE%D0%BA%D0%B8/%D0%94%D0%97_%20%D0%90%D1%80%D1%85%D0%B8%D1%82%D0%B5%D0%BA%D1%82%D1%83%D1%80%D1%8B%20%D1%81%D0%B2%D0%B5%D1%80%D1%82%D0%BE%D1%87%D0%BD%D1%8B%D1%85%20%D1%81%D0%B5%D1%82%D0%B5%D0%B9%20%E2%80%94%20%D0%BA%D0%BE%D0%BF%D0%B8%D1%8F.ipynb#X60sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     net\u001b[39m.\u001b[39;49mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/%D0%90%D0%BD%D0%B0%D1%82%D0%BE%D0%BB%D0%B8%D0%B9/Documents/GitHub/Lesson/%D0%A3%D1%80%D0%BE%D0%BA%D0%B8/%D0%94%D0%97_%20%D0%90%D1%80%D1%85%D0%B8%D1%82%D0%B5%D0%BA%D1%82%D1%83%D1%80%D1%8B%20%D1%81%D0%B2%D0%B5%D1%80%D1%82%D0%BE%D1%87%D0%BD%D1%8B%D1%85%20%D1%81%D0%B5%D1%82%D0%B5%D0%B9%20%E2%80%94%20%D0%BA%D0%BE%D0%BF%D0%B8%D1%8F.ipynb#X60sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     loss \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss(reduction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msum\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/%D0%90%D0%BD%D0%B0%D1%82%D0%BE%D0%BB%D0%B8%D0%B9/Documents/GitHub/Lesson/%D0%A3%D1%80%D0%BE%D0%BA%D0%B8/%D0%94%D0%97_%20%D0%90%D1%80%D1%85%D0%B8%D1%82%D0%B5%D0%BA%D1%82%D1%83%D1%80%D1%8B%20%D1%81%D0%B2%D0%B5%D1%80%D1%82%D0%BE%D1%87%D0%BD%D1%8B%D1%85%20%D1%81%D0%B5%D1%82%D0%B5%D0%B9%20%E2%80%94%20%D0%BA%D0%BE%D0%BF%D0%B8%D1%8F.ipynb#X60sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     net\u001b[39m.\u001b[39mtrain()\n",
            "File \u001b[1;32mc:\\Users\\Анатолий\\source\\repos\\PyTorchtest\\PyTorchtest\\TorchEnv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1161\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1157\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1158\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m   1159\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[1;32m-> 1161\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
            "File \u001b[1;32mc:\\Users\\Анатолий\\source\\repos\\PyTorchtest\\PyTorchtest\\TorchEnv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:811\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[39mif\u001b[39;00m recurse:\n\u001b[0;32m    810\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 811\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    813\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    814\u001b[0m     \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    815\u001b[0m         \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    816\u001b[0m         \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    821\u001b[0m         \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    822\u001b[0m         \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Анатолий\\source\\repos\\PyTorchtest\\PyTorchtest\\TorchEnv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:834\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    831\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    832\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    833\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> 834\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[0;32m    835\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    836\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
            "File \u001b[1;32mc:\\Users\\Анатолий\\source\\repos\\PyTorchtest\\PyTorchtest\\TorchEnv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1159\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1156\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[0;32m   1157\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1158\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m-> 1159\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
            "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torchvision as tv\n",
        "from torchsummary import summary\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def evaluate_accuracy(data_iter, net):\n",
        "    acc_sum, n = 0, 0\n",
        "    net.eval()\n",
        "    for X, y in data_iter:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        acc_sum += (net(X).argmax(axis=1) == y).sum()\n",
        "        n += y.shape[0]\n",
        "    return acc_sum.item() / n\n",
        "\n",
        "def train(net, train_iter, test_iter, trainer, num_epochs):\n",
        "    net.to(device)\n",
        "    loss = nn.CrossEntropyLoss(reduction='sum')\n",
        "    net.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
        "        \n",
        "        for i, (X, y) in enumerate(train_iter):\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            trainer.zero_grad()\n",
        "            y_hat = net(X)\n",
        "            l = loss(y_hat, y)\n",
        "            l.backward()\n",
        "            trainer.step()\n",
        "            train_l_sum += l.item()\n",
        "            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\n",
        "            n += y.shape[0]\n",
        "\n",
        "            if i % 10 == 0:\n",
        "                print(f\"Step {i}. time since epoch: {time.time() -  start:.3f}. \" \n",
        "                    f\"Train acc: {train_acc_sum / n:.3f}. Train Loss: {train_l_sum / n:.3f}\")\n",
        "        test_acc = evaluate_accuracy(test_iter, net.to(device))\n",
        "        print('-' * 20)\n",
        "        print(f'epoch {epoch + 1}, loss {train_l_sum / n:.4f}, train acc {train_acc_sum / n:.3f}'\n",
        "              f', test acc {test_acc:.3f}, time {time.time() - start:.1f} sec')\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Define your datasets and data loaders here\n",
        "BATCH_SIZE = 192\n",
        "\n",
        "# Define transformations for your datasets here\n",
        "transoforms_emnist = tv.transforms.Compose([\n",
        "    tv.transforms.Resize((224, 224)),\n",
        "    tv.transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Example: EMNIST balanced dataset\n",
        "train_dataset_emnist = tv.datasets.EMNIST('../data', split='balanced', train=True, download=True, transform=transoforms_emnist)\n",
        "test_dataset_emnist = tv.datasets.EMNIST('../data', split='balanced', train=False, download=True, transform=transoforms_emnist)\n",
        "\n",
        "train_iter_emnist = torch.utils.data.DataLoader(train_dataset_emnist, batch_size=BATCH_SIZE)\n",
        "test_iter_emnist = torch.utils.data.DataLoader(test_dataset_emnist, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Define your model architectures here\n",
        "\n",
        "# Example: ResNet18\n",
        "model_resnet18 = tv.models.resnet18(pretrained=True)\n",
        "for param in model_resnet18.parameters():\n",
        "    param.requires_grad = False\n",
        "model_resnet18.fc = nn.Linear(in_features=512, out_features=10)\n",
        "trainer_resnet18 = torch.optim.Adam(model_resnet18.fc.parameters(), lr=0.001)\n",
        "\n",
        "# Example: VGG16\n",
        "model_vgg16 = tv.models.vgg16(pretrained=True)\n",
        "for param in model_vgg16.parameters():\n",
        "    param.requires_grad = False\n",
        "model_vgg16.classifier = nn.Sequential(\n",
        "    nn.Linear(25088, 4096),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(4096, 10)\n",
        ")\n",
        "trainer_vgg16 = torch.optim.Adam(model_vgg16.classifier.parameters(), lr=0.001)\n",
        "\n",
        "# Example: DenseNet161\n",
        "model_densenet161 = tv.models.densenet161(pretrained=True)\n",
        "for param in model_densenet161.parameters():\n",
        "    param.requires_grad = False\n",
        "model_densenet161.classifier = nn.Linear(in_features=2208, out_features=10)\n",
        "trainer_densenet161 = torch.optim.Adam(model_densenet161.classifier.parameters(), lr=0.001)\n",
        "\n",
        "# Example: InceptionV3\n",
        "BATCH_SIZE = 192\n",
        "transforms_inception = tv.transforms.Compose([\n",
        "    tv.transforms.Grayscale(3),\n",
        "    tv.transforms.Resize((299, 299)),\n",
        "    tv.transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_dataset_inception = tv.datasets.EMNIST('.', train=True, transform=transforms_inception, download=True, split='mnist')\n",
        "test_dataset_inception = tv.datasets.EMNIST('.', train=False, transform=transforms_inception, download=True, split='mnist')\n",
        "\n",
        "train_iter_inception = torch.utils.data.DataLoader(train_dataset_inception, batch_size=BATCH_SIZE)\n",
        "test_iter_inception = torch.utils.data.DataLoader(test_dataset_inception, batch_size=BATCH_SIZE)\n",
        "\n",
        "model_inception_v3 = tv.models.inception_v3(pretrained=True)\n",
        "for param in model_inception_v3.parameters():\n",
        "    param.requires_grad = False\n",
        "model_inception_v3.fc = nn.Linear(in_features=2048, out_features=10)\n",
        "trainer_inception_v3 = torch.optim.Adam(model_inception_v3.fc.parameters(), lr=0.001)\n",
        "\n",
        "# Compare the models and plot training loss\n",
        "def compare_models(models, train_iters, test_iters, trainers, num_epochs, model_names):\n",
        "    train_losses = []\n",
        "    test_accuracies = []\n",
        "\n",
        "    for i, model in enumerate(models):\n",
        "        print(f\"Training {model_names[i]}...\")\n",
        "        train_loss = train(model, train_iters[i], test_iters[i], trainers[i], num_epochs)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        test_acc = evaluate_accuracy(test_iters[i], model.to(device))\n",
        "        test_accuracies.append(test_acc)\n",
        "\n",
        "    # Plot training loss for each model\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    for i, loss in enumerate(train_losses):\n",
        "        plt.plot(loss, label=model_names[i])\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.title('Training Loss Comparison')\n",
        "    plt.show()\n",
        "\n",
        "    # Create a table to compare test accuracies\n",
        "    print(\"| Model | Test Accuracy |\")\n",
        "    print(\"| - | - |\")\n",
        "    for i in range(len(model_names)):\n",
        "        print(f\"| {model_names[i]} | {test_accuracies[i]:.3f} |\")\n",
        "\n",
        "# Define your models, train iterators, test iterators, trainers, and model names here\n",
        "models = [model_resnet18, model_vgg16, model_densenet161, model_inception_v3]\n",
        "train_iters = [train_iter_emnist, train_iter_emnist, train_iter_emnist, train_iter_inception]\n",
        "test_iters = [test_iter_emnist, test_iter_emnist, test_iter_emnist, test_iter_inception]\n",
        "trainers = [trainer_resnet18, trainer_vgg16, trainer_densenet161, trainer_inception_v3]\n",
        "model_names = ['ResNet18', 'VGG16', 'DenseNet161', 'InceptionV3']\n",
        "\n",
        "compare_models(models, train_iters, test_iters, trainers, num_epochs=10, model_names=model_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
